{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Embedding, LSTM, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from random import shuffle, sample\n",
    "import datetime\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle, sample\n",
    "import  matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "#create sample weights\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.utils import compute_class_weight\n",
    "import os\n",
    "os.chdir('/home/saul/bugpred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 5 #400 # number of words in a row. Input words.\n",
    "batch_size = 200 #32 #32 #200 gave the best results\n",
    "embedding_dims = 500 #300 #5 #300\n",
    "epochs = 150 #best result is with 20\n",
    "num_neurons = 251 #50\n",
    "sample_size =  997 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcbow(dataset):\n",
    "\n",
    "    sentences = []\n",
    "    vectorised_codes = []\n",
    "    print(\"Cbow called\")\n",
    "\n",
    "    #bugs = pd.read_csv('bug-metrics.csv', sep= ',')\n",
    "    #print(bugs.columns)\n",
    "\n",
    "    ast = [row.split('::') for row in dataset['classname']]\n",
    "    #print('ASTs ', ast[:2])\n",
    "    #the imput to the cbow is list of list of each line\n",
    "    #size of the word vector of a given token must be equal to embedding_dim of the LSTM model\n",
    "    cbowmodel = Word2Vec(ast, min_count=1, size= embedding_dims, workers=3, window=3, sg=0)\n",
    "    #print(ast[:2])\n",
    "    print (' CBOW model ', cbowmodel)\n",
    "    \n",
    "    #Test cbow model\n",
    "    print(\"Test CBOW on the data\")\n",
    "    print(cbowmodel['eclipse'])\n",
    "    \n",
    "    classes = dataset['classname']\n",
    "\n",
    "    for codes in classes:\n",
    "\n",
    "        linecode = []\n",
    "        tokens = codes.split('::')\n",
    "        #print(tokens)\n",
    "        sentences.append(tokens)\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                #print(\"Token \", token)\n",
    "                #linecode.append(token)\n",
    "                #print(\"Word Vector \", len(cbowmodel[token]))\n",
    "                linecode.append(cbowmodel[token])\n",
    "            except KeyError:\n",
    "                pass\n",
    "        vectorised_codes. append(linecode)\n",
    "\n",
    "    return vectorised_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_trunc(data, maxlen):\n",
    "    new_data = []\n",
    "    zero_vector = []\n",
    "\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "\n",
    "    for sample in data:\n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(temp)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(LSTM(num_neurons, return_sequences=True, input_shape=(maxlen , embedding_dims))),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')  # two class\n",
    "    \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstmModel(vectorised_data, target):\n",
    "\n",
    "    split_point =  int(len(vectorised_data) * .7)\n",
    "    print('Split Point ', split_point)\n",
    "\n",
    "    #split data into training and testing\n",
    "    x_train = vectorised_data[:split_point]\n",
    "    y_train = target[:split_point]\n",
    "\n",
    "    x_test = vectorised_data[split_point:]\n",
    "    y_test = target[split_point:]\n",
    "\n",
    "    #make each point of data of uniform lenght\n",
    "    x_train = pad_trunc(x_train, maxlen)\n",
    "    x_test = pad_trunc(x_test, maxlen)\n",
    "\n",
    "    #reshape data into a numpy structure\n",
    "    \n",
    "    print(\"X_TRAIN Reshape Started \")\n",
    "    print(f' Training data Size: {len(x_train)}')\n",
    "    print(\"Number of word tokens \", maxlen)\n",
    "    print(\"Embedding Dims \", embedding_dims)\n",
    "\n",
    "\n",
    "    x_train = np.reshape(x_train, (len(x_train), maxlen, embedding_dims))\n",
    "    print(\"X_TRAIN Reshape Completed \")\n",
    "    #y_train = np.array(y_train)\n",
    "    y_train = to_categorical(y_train, 2)\n",
    "\n",
    "    x_test = np.reshape(x_test, (len(x_test), maxlen, embedding_dims))\n",
    "    #y_test = np.array(y_test)\n",
    "    y_test = to_categorical(y_test, 2)\n",
    "    #print(f'Y_TEST DATA: {y_test}')\n",
    "    print((f'Y_TEST_DATA LENGHT{len(y_test)}'))\n",
    "    print(\"Data Reshape Ended \")\n",
    "    \n",
    "    model = create_model()\n",
    "\n",
    "    rmsprob = RMSprop(learning_rate=0.0001, rho=0.4) # use learning rate to improve the accuracy of the model\n",
    "    adam = Adam(lr=0.001)\n",
    "    #sgd = SGD(lr=0.1)\n",
    "    #sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.2, nesterov=True)    \n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer= rmsprob, metrics=['accuracy'])\n",
    "    \n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    fitmodel(model, x_train, y_train, x_test, y_test, batch_size, epochs, [tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitmodel(model, x_train, y_train, x_test, y_test, batch_size, epochs, tensorboard_callback):\n",
    "\n",
    "    print('Y Test ', y_test.shape)\n",
    "\n",
    "    cls_weight_dict = [{0: 1, 1: 1}, {0: 1, 1: 80}] #two class mapping of weights\n",
    "    val_sample_weights = compute_sample_weight(cls_weight_dict, y_test)\n",
    "\n",
    "    weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              #sample_weight = weights,\n",
    "              class_weight = {0 : 1. , 1: 80.},\n",
    "              #class_weight={0: 1., 1: 100.},\n",
    "              validation_data=(x_test, y_test, val_sample_weights),\n",
    "              callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset():\n",
    "\n",
    "    dataset = pd.read_csv('bug-metrics.csv', sep= ',')\n",
    "\n",
    "    #keep = ['classname', 'bugs']\n",
    "    dataset = dataset.sample(n= sample_size, replace= True, random_state=1)\n",
    "\n",
    "    #shuffle(dataset)\n",
    "    #dataset.to_csv('sampledataset.csv')\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cbow called\n",
      " CBOW model  Word2Vec(vocab=648, size=500, alpha=0.025)\n",
      "Test CBOW on the data\n",
      "[ 4.33608107e-02  9.74239632e-02  6.72205612e-02  1.75349936e-01\n",
      " -2.81045586e-02  1.40621200e-01 -1.42611712e-01  7.23332763e-02\n",
      "  7.40287900e-02 -3.82003076e-02  3.80077660e-02 -7.58453384e-02\n",
      " -2.02103835e-02  9.86236185e-02  2.14544404e-02 -3.24227102e-02\n",
      " -2.98386123e-02  1.05249062e-01  5.18811122e-02 -1.39894694e-01\n",
      "  9.17500816e-03 -1.25790432e-01  7.72704259e-02 -1.00175448e-01\n",
      "  1.79270044e-01  1.06193079e-02 -8.35145358e-03  2.10743956e-02\n",
      " -1.18528508e-01 -4.27872390e-02  1.99522879e-02  1.60560876e-01\n",
      "  1.14116684e-01  9.70501229e-02 -1.86513029e-02  8.15443322e-02\n",
      " -5.26925996e-02 -1.41300401e-02  1.35928512e-01  9.87130497e-03\n",
      "  8.33240747e-02 -2.53285170e-02  5.10498695e-02 -7.52034932e-02\n",
      "  1.84580521e-03 -1.02309927e-01  2.76369657e-02 -4.22766432e-02\n",
      "  5.11343479e-02 -1.12836510e-02  3.58895510e-02  9.87377465e-02\n",
      "  1.81819618e-01  1.27283931e-01 -1.26040980e-01 -4.48674113e-02\n",
      "  9.32855383e-02  3.80150229e-02 -8.96032006e-02  2.00299606e-01\n",
      " -1.23771258e-01 -3.98046151e-02 -5.77242561e-02  4.62287478e-03\n",
      "  1.33136930e-02  6.27533644e-02 -2.32537370e-02 -2.55513024e-02\n",
      "  3.09122819e-02 -6.35761470e-02  2.00300142e-01  4.83520515e-02\n",
      "  2.51821056e-02 -7.15861768e-02  1.52798016e-02  2.31463425e-02\n",
      " -4.75205109e-02 -1.15782142e-01  1.22552477e-01 -7.12302029e-02\n",
      "  2.53386032e-02 -2.81415526e-02 -6.41718060e-02 -2.31860504e-02\n",
      " -1.18343726e-01  1.10014014e-01  2.38408428e-02  1.67906895e-01\n",
      "  1.40170768e-01  4.47823107e-02 -4.39361781e-02  4.43815142e-02\n",
      " -7.18262047e-02  3.61430831e-02 -6.70695538e-03  2.26317309e-02\n",
      " -9.74079669e-02  2.75645480e-02 -1.00490808e-01 -9.58846323e-03\n",
      "  4.02464569e-02 -2.02801391e-01 -6.25241399e-02  3.87384668e-02\n",
      "  1.14681847e-01 -2.52616145e-02 -5.60506433e-02 -1.43391863e-01\n",
      "  5.00405580e-02  3.87549773e-02  1.45099731e-03 -2.45003939e-01\n",
      "  1.30626589e-01 -2.57468410e-02 -1.63645204e-02 -4.57828641e-02\n",
      " -7.73565983e-03 -9.23231319e-02 -7.94452652e-02  1.18724974e-02\n",
      "  2.26765629e-02 -2.34457869e-02  2.20040735e-02 -7.12804645e-02\n",
      "  3.79456556e-03  2.58036815e-02  3.35432701e-02  3.68794762e-02\n",
      "  5.73088117e-02  5.03583029e-02 -4.71924841e-02 -8.74233320e-02\n",
      "  2.50177085e-02  6.59334883e-02 -5.57517782e-02  2.62449179e-02\n",
      "  1.00666314e-01 -9.80756246e-04 -3.93516757e-03 -2.17408687e-02\n",
      " -5.52471839e-02  2.00137973e-01  8.79817158e-02 -1.12085536e-01\n",
      "  3.22730243e-02  1.26821950e-01  7.76440725e-02  1.77390844e-01\n",
      "  1.66872427e-01 -2.51086317e-02  8.72947797e-02  8.55981261e-02\n",
      " -1.47865647e-02  7.97828734e-02  6.19340017e-02  2.44140234e-02\n",
      "  4.30942103e-02 -3.90907712e-02 -1.42059783e-02  1.08669437e-01\n",
      " -9.72443745e-02 -7.54509727e-03 -1.56491429e-01 -3.44567001e-02\n",
      " -1.42622396e-01 -1.27586082e-01  7.88572803e-03  6.25093207e-02\n",
      " -1.01856468e-02 -4.30366993e-02  1.14228278e-02  8.80370513e-02\n",
      "  5.77949099e-02  8.16233903e-02  1.71329062e-02 -5.75984716e-02\n",
      "  3.31224687e-02  4.76735719e-02 -6.37038425e-02 -1.03910618e-01\n",
      "  9.69046205e-02 -2.16185674e-02  7.81441107e-02  1.00521810e-01\n",
      " -1.23220040e-02 -7.79870600e-02  1.53851276e-02 -6.85158074e-02\n",
      "  5.25319427e-02  5.76700922e-03 -9.51758549e-02 -6.25915686e-03\n",
      "  5.75970486e-02 -7.16147721e-02 -3.34086977e-02 -1.74323358e-02\n",
      "  4.90403958e-02 -7.73484707e-02  3.43130827e-02  1.05869090e-02\n",
      "  6.89661503e-02 -9.23478231e-02  3.54288965e-02  5.34570068e-02\n",
      " -8.38954598e-02 -2.15944313e-02  1.98533256e-02 -1.56842798e-01\n",
      "  1.12465635e-01  2.16724761e-02 -5.88308834e-02  3.59940678e-02\n",
      " -4.82281148e-02  2.90581863e-02  2.11864002e-02 -1.03092857e-01\n",
      " -8.88632610e-03 -2.46946160e-02 -4.69267108e-02 -6.10768348e-02\n",
      " -4.40949649e-02  7.09374323e-02  9.85743552e-02 -2.01157015e-02\n",
      " -1.22725600e-02 -6.65573999e-02  1.83569044e-01  3.65735851e-02\n",
      " -1.61478315e-02 -4.43758890e-02 -5.99330589e-02 -1.76358465e-02\n",
      "  3.61162275e-02  2.00946778e-01  1.40738755e-01 -8.03960562e-02\n",
      "  8.12169313e-02 -1.70193128e-02 -4.19977643e-02 -1.41476793e-03\n",
      "  6.26870170e-02  1.33595482e-01 -4.20185700e-02 -4.35554236e-02\n",
      "  3.31695639e-02 -6.33683801e-02 -1.09802119e-01 -3.80288847e-02\n",
      " -3.94197851e-02  2.87675820e-02  8.23622718e-02  7.79544339e-02\n",
      " -1.89774893e-02 -9.31875035e-02 -4.57023978e-02  5.53318039e-02\n",
      " -5.88184968e-02 -2.08246498e-03 -6.92843571e-02  2.50404142e-02\n",
      "  1.28768301e-02 -9.55849048e-03 -5.31448983e-02  8.88970792e-02\n",
      "  3.73983607e-02  3.88481319e-02 -7.25364387e-02 -2.21589338e-02\n",
      " -3.31789069e-02 -5.38027436e-02  3.97233069e-02  1.64083436e-01\n",
      "  1.02113515e-01 -6.37671575e-02  4.71316511e-03  1.20440066e-01\n",
      "  1.06152400e-01  1.24137484e-01 -2.75997613e-02  2.01146511e-04\n",
      " -1.18822232e-02 -4.97825295e-02 -1.15428148e-02 -5.61448038e-02\n",
      " -4.25961986e-03 -3.27593237e-02  4.45380099e-02  1.21563368e-01\n",
      "  8.69404897e-02  2.68844701e-02 -5.34448512e-02  4.46476042e-02\n",
      "  1.71375394e-01 -3.25261317e-02  8.49383697e-02  2.20168885e-02\n",
      " -2.91742980e-02 -4.48010378e-02 -1.36146292e-01  7.37992674e-02\n",
      " -4.00045328e-02  2.99191419e-02  1.05174609e-01 -4.38973457e-02\n",
      " -6.01212382e-02  8.25881027e-03 -3.92703293e-03 -9.75537300e-02\n",
      " -1.12732999e-01  1.55467361e-01 -2.30928510e-02 -8.63543432e-03\n",
      " -5.13677895e-02 -4.30815071e-02 -7.26652844e-03 -8.53708163e-02\n",
      " -9.96275619e-02 -4.46703434e-02 -4.06576991e-02  7.14684427e-02\n",
      "  3.90157998e-02 -6.64722621e-02 -3.16022895e-02 -7.37629831e-02\n",
      " -8.94647390e-02  4.89692688e-02 -1.23649880e-01  4.06113528e-02\n",
      " -9.95767489e-02 -1.44228879e-02 -5.37711475e-03  1.77278521e-03\n",
      "  2.51722820e-02  4.15733568e-02  8.92870054e-02 -1.49051905e-01\n",
      "  3.79781984e-02 -9.01059806e-02 -2.78017316e-02 -6.56000823e-02\n",
      "  6.45863786e-02 -1.46038175e-01 -1.15952842e-01  3.52494121e-02\n",
      " -1.05229288e-01  8.52240548e-02  3.95754725e-02  4.89598401e-02\n",
      " -1.49784327e-01  3.33935171e-02 -1.25466818e-02  3.54252495e-02\n",
      " -1.10627331e-01  3.86654176e-02 -2.62872726e-02 -5.21494374e-02\n",
      "  2.59707961e-02  6.99225292e-02 -8.23324993e-02 -1.13194838e-01\n",
      " -6.48802295e-02  7.84065947e-02  2.82962760e-03 -2.71812249e-02\n",
      " -8.39766413e-02  1.18901700e-01  5.08433208e-02  6.69220835e-02\n",
      "  9.44073424e-02  2.92099938e-02 -2.13854499e-02 -3.08494084e-02\n",
      " -8.91523063e-02 -3.84919159e-02 -7.10130855e-02 -4.75011691e-02\n",
      " -1.20157644e-01  5.62758148e-02 -1.36187198e-02 -4.40709777e-02\n",
      "  3.87801304e-02 -4.51363474e-02  2.13412512e-02  9.74454880e-02\n",
      "  1.23618431e-01  1.72072789e-03 -3.65747362e-02  2.03568786e-02\n",
      " -7.46688694e-02 -1.48338348e-01 -6.85349628e-02 -6.01283833e-03\n",
      " -4.08317931e-02 -1.07932024e-01  1.33657396e-01  4.26896140e-02\n",
      " -1.12101033e-01  4.13085669e-02 -3.21904197e-02 -6.88917115e-02\n",
      "  5.56192696e-02  1.40356749e-01  1.18421942e-01  1.34242520e-01\n",
      "  3.46834138e-02  3.72080728e-02  2.21374277e-02  2.40129735e-02\n",
      "  4.82418872e-02  7.79832676e-02 -5.23612611e-02 -9.35887843e-02\n",
      "  4.88187820e-02 -4.40293215e-02 -2.90927086e-02 -5.71904797e-03\n",
      "  8.94384757e-02  1.98673513e-02  6.75717890e-02 -8.95187408e-02\n",
      " -1.23154221e-03  5.10304533e-02 -1.08226880e-01  2.40548626e-02\n",
      " -1.27425447e-01  5.53031489e-02 -1.82235956e-01 -9.73381773e-02\n",
      " -1.04900070e-01 -6.95921257e-02  1.24806445e-02 -9.76210576e-04\n",
      " -1.40022680e-01  1.19215444e-01 -1.23427935e-01  1.68372132e-03\n",
      "  3.86381596e-02  9.68698487e-02  2.27453392e-02  5.81895821e-02\n",
      " -7.18514547e-02 -1.51358068e-01 -5.37417531e-02  4.97243255e-02\n",
      "  8.32611173e-02  8.78236890e-02 -2.92801708e-02  5.00081815e-02\n",
      "  1.27399825e-02  4.22335751e-02  1.08698502e-01 -1.80095568e-01\n",
      "  8.11715648e-02 -1.64550953e-02 -2.91784573e-02 -1.04444109e-01\n",
      " -2.28109490e-02  7.07834885e-02  1.80688336e-01  7.52940848e-02\n",
      " -4.28658500e-02 -5.19140363e-02 -1.63675383e-01 -6.58602715e-02\n",
      " -2.03823410e-02  1.30982362e-02 -1.52095165e-02 -9.84030440e-02\n",
      "  2.24380996e-02  2.81784479e-02  6.38001487e-02  1.68064311e-01\n",
      " -1.01093523e-01  8.95942282e-03 -5.92674725e-02 -1.57750413e-01\n",
      " -4.38220054e-02 -5.15988097e-02 -4.74383980e-02 -2.00275667e-02\n",
      "  3.31120491e-02  1.17534921e-02  2.06604093e-01 -4.69750986e-02\n",
      "  2.32151262e-02  4.85836864e-02 -8.19955530e-05  1.62616804e-01\n",
      "  1.51361004e-02  1.24364994e-01  9.72505286e-03  3.92338596e-02\n",
      "  9.87119749e-02 -9.57694184e-03  9.98263657e-02 -3.03854048e-02\n",
      "  2.27438007e-02 -1.04527578e-01 -1.53242216e-01 -1.39601985e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saul/.local/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/saul/.local/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collect_expected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-37797883417c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorised_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetcbow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_expected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Biased two classes {198, 2} lenght is 200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#print (target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlstmModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorised_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collect_expected' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = getDataset()\n",
    "#getmaxlen(dataset)\n",
    "vectorised_data = getcbow(dataset)\n",
    "\n",
    "target = collect_expected(dataset) #Biased two classes {198, 2} lenght is 200\n",
    "#print (target)\n",
    "lstmModel(vectorised_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7624), started 0:02:06 ago. (Use '!kill 7624' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3ae4a4b4b387e0a2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3ae4a4b4b387e0a2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
